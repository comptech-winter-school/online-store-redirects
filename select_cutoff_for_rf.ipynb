{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 февраля, подбор параметров для случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка и обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_to_data = './data/data_with_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.make_vectoizer import make_vectorizer\n",
    "from utils.io_custom import dump_pickle_object\n",
    "\n",
    "\n",
    "train = pd.read_csv('./data/clear_data/train_data.csv')\n",
    "new_vectorizer = make_vectorizer(train_data=train,\n",
    "                                 ngram_range=(3,4),\n",
    "                                 max_features=4000,\n",
    "                                 analyzer='char_wb')\n",
    "dump_pickle_object('./data/redir/vectorizer.obj', new_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.feature_generation import get_data_with_feature\n",
    "\n",
    "\n",
    "train = get_data_with_feature(train, './data/redir')\n",
    "train['cosine_dist'] = train['cosine_dist'].fillna(train['cosine_dist'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = pd.read_csv('./data/clear_data/validate_data.csv')\n",
    "validate = get_data_with_feature(validate, './data/redir')\n",
    "validate['cosine_dist'] = validate['cosine_dist'].fillna(validate['cosine_dist'].mean())\n",
    "\n",
    "X_validate = validate.drop(columns=['is_redirect'])\n",
    "y_validate = validate['is_redirect']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train.drop(columns=['is_redirect']),\n",
    "    train['is_redirect'],\n",
    "    stratify=train['is_redirect'],\n",
    "    random_state=0,\n",
    "    shuffle=True,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров для случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "             param_grid={'max_depth': [2, 5, 7, 10],\n",
       "                         'n_estimators': [10, 20, 30]})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_rf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': range(10, 100, 10),\n",
    "    'max_depth': range(1, 12),\n",
    "    'min_samples_leaf': range(1, 7),\n",
    "    'min_samples_split': range(2, 9),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight': ['balanced', 'balanced_subsample']\n",
    "}\n",
    "\n",
    "grid_searh_cv_clf = GridSearchCV(base_rf,\n",
    "                                 parametrs,\n",
    "                                 cv=5)\n",
    "\n",
    "grid_searh_cv_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, n_estimators=30, random_state=1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_searh_cv_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf = grid_searh_cv_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ 5 используемых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>feature_importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cosine_dist</td>\n",
       "      <td>0.281431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lev_dist</td>\n",
       "      <td>0.223942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how_match_brands_name_in_query</td>\n",
       "      <td>0.119665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>len_of_query</td>\n",
       "      <td>0.059715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>len_of_category</td>\n",
       "      <td>0.043659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          features  feature_importances\n",
       "14                     cosine_dist             0.281431\n",
       "13                        lev_dist             0.223942\n",
       "4   how_match_brands_name_in_query             0.119665\n",
       "0                     len_of_query             0.059715\n",
       "2                  len_of_category             0.043659"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важность фич (как часто данная фича использовалась и давала максимальное снижеие неопределенности)\n",
    "feature_importances_df = pd.DataFrame({\n",
    "        'features': list(X_train),\n",
    "        'feature_importances': best_rf.feature_importances_\n",
    "}).sort_values('feature_importances', ascending=False)\n",
    "\n",
    "feature_importances_df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики для обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF from grid searcher cv:\n",
      "\n",
      "Metrics for train:\n",
      "roc_auc_score 0.9728\n",
      "f1_score 0.9714\n",
      "accuracy_score 0.9769\n",
      "\n",
      "Metrics for test:\n",
      "roc_auc_score 0.9637\n",
      "f1_score 0.9603\n",
      "accuracy_score 0.9678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, confusion_matrix\n",
    "\n",
    "\n",
    "predicts_for_train = best_rf.predict(X_train)\n",
    "predicts_for_test = best_rf.predict(X_test)\n",
    "\n",
    "print(\"RF from grid searcher cv:\")\n",
    "print(\"\\nMetrics for train:\")\n",
    "for metric in [roc_auc_score, f1_score, accuracy_score]:\n",
    "    print(metric.__name__, round(metric(y_train, predicts_for_train), 4))\n",
    "\n",
    "print(\"\\nMetrics for test:\")\n",
    "for metric in [roc_auc_score, f1_score, accuracy_score]:\n",
    "    print(metric.__name__, round(metric(y_test, predicts_for_test), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики для валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for validate with default cutoff:\n",
      "roc_auc_score 0.5743\n",
      "f1_score 0.6054\n",
      "accuracy_score 0.5085\n",
      "Confusion matrix for validate:\n",
      "[[ 31 109]\n",
      " [  7  89]]\n"
     ]
    }
   ],
   "source": [
    "predicts_for_validate = best_rf.predict(X_validate)\n",
    "\n",
    "print(\"\\nMetrics for validate with default cutoff:\")\n",
    "for metric in [roc_auc_score, f1_score, accuracy_score]:\n",
    "    print(metric.__name__, round(metric(y_validate, predicts_for_validate), 4))\n",
    "    \n",
    "print('Confusion matrix for validate:')\n",
    "print(confusion_matrix(y_validate, predicts_for_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_probabilities = best_rf.predict_proba(X_validate)\n",
    "custom_cutoff = 0.5\n",
    "predicts_with_custom_cutoff = []\n",
    "\n",
    "for zero_prob, one_prob in class_probabilities:\n",
    "        predicts_with_custom_cutoff.append(1 if one_prob > custom_cutoff else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for validate with custom cutoff: 0.5\n",
      "roc_auc_score 0.5743\n",
      "f1_score 0.6054\n",
      "accuracy_score 0.5085\n",
      "Confusion matrix for validate:\n",
      "[[ 31 109]\n",
      " [  7  89]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMetrics for validate with custom cutoff:\")\n",
    "for metric in [roc_auc_score, f1_score, accuracy_score]:\n",
    "    print(metric.__name__, round(metric(y_validate, predicts_with_custom_cutoff), 4))\n",
    "    \n",
    "print('Confusion matrix for validate:')\n",
    "print(confusion_matrix(y_validate, predicts_with_custom_cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max f1_score is: 0.6164874551971327\n",
      "Cutoff is: 0.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class_probabilities = best_rf.predict_proba(X_validate)\n",
    "all_f1_scores = []\n",
    "all_cutoffs = list(np.arange(0, 1, 0.0001))\n",
    "\n",
    "for current_cutoff in all_cutoffs:\n",
    "    predicts_with_current_cutoff = []\n",
    "\n",
    "    for zero_prob, one_prob in class_probabilities:\n",
    "        predicts_with_current_cutoff.append(1 if one_prob > current_cutoff else 0)\n",
    "\n",
    "    all_f1_scores.append(f1_score(y_validate, np.array(predicts_with_current_cutoff)))\n",
    "    \n",
    "max_f1_score = max(all_f1_scores)\n",
    "cutoff_for_max_f1_score = all_cutoffs[np.argmax(all_f1_scores)]\n",
    "\n",
    "print(\"Max f1_score is:\", max_f1_score)\n",
    "print(\"Cutoff is:\", cutoff_for_max_f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики для валидационной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics for validate with custom cutoff: 0.6\n",
      "roc_auc_score 0.6015\n",
      "f1_score 0.6165\n",
      "accuracy_score 0.5466\n",
      "Confusion matrix for validate with custom cutoff: 0.6\n",
      "[[43 97]\n",
      " [10 86]]\n"
     ]
    }
   ],
   "source": [
    "predicts_with_custom_cutoff = []\n",
    "\n",
    "for zero_prob, one_prob in class_probabilities:\n",
    "        predicts_with_custom_cutoff.append(1 if one_prob > cutoff_for_max_f1_score else 0)\n",
    "\n",
    "print('\\nMetrics for validate with custom cutoff:', cutoff_for_max_f1_score)\n",
    "for metric in [roc_auc_score, f1_score, accuracy_score]:\n",
    "    print(metric.__name__, round(metric(y_validate, predicts_with_custom_cutoff), 4))\n",
    "    \n",
    "print('Confusion matrix for validate with custom cutoff:', cutoff_for_max_f1_score)\n",
    "print(confusion_matrix(y_validate, predicts_with_custom_cutoff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitanaconda3virtualenv60f99e7c43554557828048e37359e600"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
